{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "data=pd.read_csv('artifacts/Cleaned_Indian_Food_Dataset.csv',usecols=['TranslatedRecipeName','Cleaned-Ingredients','TranslatedInstructions','Ingredient-count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ingredients(ingredient_string):\n",
    "    # Remove anything inside parentheses\n",
    "    cleaned_string = re.sub(r'\\s*\\(.*?\\)\\s*', '', ingredient_string)\n",
    "    # Convert the cleaned string to a list\n",
    "    return [item.strip() for item in cleaned_string.split(',')]\n",
    "\n",
    "# Apply the function to the 'ingredients' column and create a new column 'Ingredients cleaned'\n",
    "data['Processed_Ingredients'] = data['Cleaned-Ingredients'].apply(clean_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "llm = Ollama(model='llama2')\n",
    "output_parser=StrOutputParser(\n",
    ")\n",
    "prompt=ChatPromptTemplate([\n",
    "        ('system',\"\"\"You are a chef. The user will give you a list of ingredients. You have to create an Indian Dish using those\n",
    "        ingredients only.\n",
    "        Use the following template to give your output:\n",
    "         Ingredients Used:\n",
    "            - Ingredient 1\n",
    "            - Ingredient 2\n",
    "            - other ingredients\n",
    "         Instructions:\n",
    "            - Instruction 1\n",
    "            - Instruction 2\n",
    "         Do not output anything else apart from Ingredients Used and Instructions.\n",
    "         \"\"\"),\n",
    "        (\"user\",\"Ingredients: {Ingredients}\")\n",
    "\n",
    "    ])\n",
    "\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({'Ingredients':data['Processed_Ingredients'][0]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ingredients Used:\\n\\n* Salt\\n* Amchur\\n* Karela\\n* Red chilli powder\\n* Gram flour\\n* Onion\\n* Cumin seeds\\n* Coriander powder\\n* Turmeric powder\\n\\nInstructions:\\n\\n* Heat sunflower oil in a pan over medium heat.\\n* Add cumin seeds and let them sizzle for a few seconds.\\n* Add finely chopped onion and sauté until it is translucent.\\n* Add karela (bitter gourd) and sauté for 2-3 minutes, or until it starts to soften.\\n* Add salt, red chilli powder, coriander powder, and turmeric powder, and mix well.\\n* Add gram flour (besan) and mix well.\\n* Add amchur (dried mango powder) and mix well.\\n* Cover the pan and cook for 5-7 minutes, or until the karela is cooked through and the mixture is dry.\\n* Serve hot with rice or roti.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salt',\n",
       " 'amchur',\n",
       " 'karela',\n",
       " 'red chilli powder',\n",
       " 'gram flour',\n",
       " 'onion',\n",
       " 'cumin seeds',\n",
       " 'coriander powder',\n",
       " 'turmeric powder',\n",
       " 'sunflower oil']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = response.split('\\n')\n",
    "\n",
    "gen_ingredients = []\n",
    "gen_instructions = []\n",
    "in_ingredients = False\n",
    "in_instructions = False\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip() \n",
    "    if line == \"Ingredients Used:\":\n",
    "        in_ingredients = True\n",
    "        continue\n",
    "    elif line == \"Instructions:\":\n",
    "        in_ingredients = False\n",
    "        in_instructions = True\n",
    "        continue\n",
    "    \n",
    "    if in_ingredients and line.startswith(\"*\"):\n",
    "        gen_ingredients.append(line[1:].strip())\n",
    "    elif in_instructions and line.startswith(\"*\"):\n",
    "        gen_instructions.append(line[1:].strip())\n",
    "\n",
    "data['Processed_Ingredients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "actual_ingredients=data['Processed_Ingredients'][0]\n",
    "gen_ingredients_lower = [ingredient.lower() for ingredient in gen_ingredients]\n",
    "\n",
    "total_input_ingredients = len(actual_ingredients)\n",
    "total_ingredients_used = len(gen_ingredients_lower)\n",
    "\n",
    "relevant_ingredients_used = len(set(actual_ingredients).intersection(set(gen_ingredients_lower)))\n",
    "\n",
    "precision = relevant_ingredients_used / total_ingredients_used\n",
    "recall = relevant_ingredients_used / total_input_ingredients\n",
    "\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To begin making the Masala Karela Recipe,de-seed the karela and slice.\\nDo not remove the skin as the skin has all the nutrients.\\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\\nRelease the pressure immediately and open the lids.\\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\\n']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TranslatedInstructions'][0].split('/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_instructions_cleaned='\\n '.join(gen_instructions)\n",
    "gen_instructions_cleaned\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "# Tokenize the sentences\n",
    "reference_tokens = data['TranslatedInstructions'][0].split('/n')  # Reference needs to be a list of token lists\n",
    "candidate_tokens = gen_instructions\n",
    "weights = (0.5, 0.5, 0, 0)\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu(reference_tokens, candidate_tokens,weights=weights)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heat sunflower oil in a pan over medium heat.',\n",
       " 'Add cumin seeds and let them sizzle for a few seconds.',\n",
       " 'Add finely chopped onion and sauté until it is translucent.',\n",
       " 'Add karela (bitter gourd) and sauté for 2-3 minutes, or until it starts to soften.',\n",
       " 'Add salt, red chilli powder, coriander powder, and turmeric powder, and mix well.',\n",
       " 'Add gram flour (besan) and mix well.',\n",
       " 'Add amchur (dried mango powder) and mix well.',\n",
       " 'Cover the pan and cook for 5-7 minutes, or until the karela is cooked through and the mixture is dry.',\n",
       " 'Serve hot with rice or roti.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = re.findall(r'\\* (.+)', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salt',\n",
       " 'Amchur',\n",
       " 'Karela',\n",
       " 'Red chilli powder',\n",
       " 'Gram flour',\n",
       " 'Onion',\n",
       " 'Cumin seeds',\n",
       " 'Coriander powder',\n",
       " 'Turmeric powder',\n",
       " 'Heat sunflower oil in a pan over medium heat.',\n",
       " 'Add cumin seeds and let them sizzle for a few seconds.',\n",
       " 'Add finely chopped onion and sauté until it is translucent.',\n",
       " 'Add karela (bitter gourd) and sauté for 2-3 minutes, or until it starts to soften.',\n",
       " 'Add salt, red chilli powder, coriander powder, and turmeric powder, and mix well.',\n",
       " 'Add gram flour (besan) and mix well.',\n",
       " 'Add amchur (dried mango powder) and mix well.',\n",
       " 'Cover the pan and cook for 5-7 minutes, or until the karela is cooked through and the mixture is dry.',\n",
       " 'Serve hot with rice or roti.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salt',\n",
       " 'amchur',\n",
       " 'karela',\n",
       " 'red chilli powder',\n",
       " 'gram flour',\n",
       " 'onion',\n",
       " 'cumin seeds',\n",
       " 'coriander powder',\n",
       " 'turmeric powder',\n",
       " 'sunflower oil']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Processed_Ingredients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To begin making the Masala Karela Recipe,de-seed the karela and slice.\\nDo not remove the skin as the skin has all the nutrients.\\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\\nRelease the pressure immediately and open the lids.\\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TranslatedInstructions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salt',\n",
       " 'amchur',\n",
       " 'karela',\n",
       " 'red chilli powder',\n",
       " 'gram flour',\n",
       " 'onion',\n",
       " 'cumin seeds',\n",
       " 'coriander powder',\n",
       " 'turmeric powder',\n",
       " 'sunflower oil']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Processed_Ingredients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for Llama2LLMChain\nprompt\n  Field required [type=missing, input_value={'llm': <transformers.pip... at 0x000001E5AA1EA1E0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<transformers.pipelines.t...t at 0x000001E5AA1EA1E0>, input_type=TextGenerationPipeline]\n    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<transformers.pipelines.t...t at 0x000001E5AA1EA1E0>, input_type=TextGenerationPipeline]\n    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Initialize the LLaMA model as part of LangChain\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m llama_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLlama2LLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_recipe\u001b[39m(ingredients: \u001b[38;5;28mlist\u001b[39m, cuisine: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Convert the ingredients list into a comma-separated string\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     ingredients_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ingredients)\n",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m, in \u001b[0;36mLlama2LLMChain.__init__\u001b[1;34m(self, model, tokenizer)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, tokenizer):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:215\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     emit_warning()\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\langchain_core\\load\\serializable.py:112\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\pydantic\\main.py:176\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    175\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 3 validation errors for Llama2LLMChain\nprompt\n  Field required [type=missing, input_value={'llm': <transformers.pip... at 0x000001E5AA1EA1E0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<transformers.pipelines.t...t at 0x000001E5AA1EA1E0>, input_type=TextGenerationPipeline]\n    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<transformers.pipelines.t...t at 0x000001E5AA1EA1E0>, input_type=TextGenerationPipeline]\n    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "access_token = \"\"\n",
    "\n",
    "# Specify the model\n",
    "model_name = \"openai-community/gpt2\"\n",
    "\n",
    "# Try loading the fast tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, use_auth_token=access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, use_auth_token=access_token)\n",
    "\n",
    "\n",
    "# Define a custom prompt template for generating recipes\n",
    "recipe_template = \"\"\"\n",
    "I have the following ingredients: {ingredients}.\n",
    "I want to prepare a dish from {cuisine} cuisine.\n",
    "Please generate a recipe using these ingredients with instructions.\n",
    "\n",
    "Recipe:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"ingredients\", \"cuisine\"],\n",
    "    template=recipe_template\n",
    ")\n",
    "\n",
    "# LangChain LLM wrapper for Hugging Face model\n",
    "class Llama2LLMChain(LLMChain):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        super().__init__(llm=pipeline(\"text-generation\", model=model, tokenizer=tokenizer))\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        return super()._call(inputs)\n",
    "\n",
    "# Initialize the LLaMA model as part of LangChain\n",
    "llama_chain = Llama2LLMChain(model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def generate_recipe(ingredients: list, cuisine: str) -> str:\n",
    "    # Convert the ingredients list into a comma-separated string\n",
    "    ingredients_str = ', '.join(ingredients)\n",
    "    \n",
    "    # Prepare input data for the LangChain\n",
    "    input_data = {\n",
    "        \"ingredients\": ingredients_str,\n",
    "        \"cuisine\": cuisine\n",
    "    }\n",
    "    \n",
    "    # Generate the recipe using the LLaMA model\n",
    "    response = llama_chain(input_data)\n",
    "    \n",
    "    # Extract and return the generated text\n",
    "    return response['text']\n",
    "\n",
    "ingredients = data['Processed_Ingredients'][0]\n",
    "cuisine = 'Indian'\n",
    "\n",
    "recipe = generate_recipe(ingredients, cuisine)\n",
    "print(recipe)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_recipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
