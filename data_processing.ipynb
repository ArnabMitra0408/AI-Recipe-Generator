{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "data=pd.read_csv('artifacts/Cleaned_Indian_Food_Dataset.csv',usecols=['TranslatedRecipeName','Cleaned-Ingredients','TranslatedInstructions','Ingredient-count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ingredients(ingredient_string):\n",
    "    # Remove anything inside parentheses\n",
    "    cleaned_string = re.sub(r'\\s*\\(.*?\\)\\s*', '', ingredient_string)\n",
    "    # Convert the cleaned string to a list\n",
    "    return [item.strip() for item in cleaned_string.split(',')]\n",
    "\n",
    "# Apply the function to the 'ingredients' column and create a new column 'Ingredients cleaned'\n",
    "data['Processed_Ingredients'] = data['Cleaned-Ingredients'].apply(clean_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "llm = Ollama(model='llama3.2')\n",
    "\n",
    "prompt=ChatPromptTemplate([\n",
    "        ('system', \"\"\"\n",
    "        You are a master Indian chef specializing in traditional Indian cuisine. The user will give you a list of ingredients, and you are required to create a genuine Indian dish using only those ingredients.\n",
    "        Use the following structure for your response:\n",
    "        \n",
    "        Ingredients Used:\n",
    "            - Ingredient 1\n",
    "            - Ingredient 2\n",
    "            - (List all ingredients provided by the user)\n",
    "        \n",
    "        Instructions:\n",
    "            - Step 1: (Describe each step of the cooking process in detail)\n",
    "            - Step 2: (Continue outlining the steps until the dish is complete)\n",
    "     \n",
    "        Below are sample instructions for a dish provided. Form your sentences in a similar manner.\n",
    "        - Step 1: To prepare gourd raita, prepare all the ingredients first.\n",
    "        - Step 2: Add grated gourd, cucumber, curd, green chillies, salt, cumin powder and coriander in a large bowl.\n",
    "        - Step 3: Mix well and your raita is ready.\n",
    "        - Step 4: Serve gourd raita with Garlic Dal, gourd elder greens and phulka for dinner.\n",
    "        \n",
    "        Keep your response focused on 'Ingredients Used' and 'Instructions'. Avoid adding additional explanations or extra information.\n",
    "    \"\"\"),\n",
    "        (\"user\",\"Ingredients: {Ingredients}\")\n",
    "\n",
    "    ])\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({'Ingredients': data['Processed_Ingredients'][0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ingredients Used:\\n            - Salt\\n            - Amchur\\n            - Karela\\n            - Red chilli powder\\n            - Gram flour\\n            - Onion\\n            - Cumin seeds\\n            - Coriander powder\\n            - Turmeric powder\\n            - Sunflower oil\\n\\nInstructions:\\n            - Step 1: Soak the gram flour in water for about 30 minutes to make it smooth and easy to grind.\\n            - Step 2: Heat sunflower oil in a pan over medium heat, add cumin seeds and let them sizzle for a few seconds.\\n            - Step 3: Add chopped onion and sauté until they are translucent and lightly browned.\\n            - Step 4: Grind the soaked gram flour into a fine paste with turmeric powder, red chilli powder, coriander powder, and salt.\\n            - Step 5: Add the ground spice mixture to the pan with onion and mix well.\\n            - Step 6: Slice the karela into thin rounds, remove excess moisture by salting and draining.\\n            - Step 7: Dip the sliced karela in the gram flour paste, coating them evenly, then add the amchur powder for extra flavor.\\n            - Step 8: Heat some oil in a pan over medium heat, add the coated karela slices and fry until they are golden brown and crispy.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients:\n",
      "0. Salt\n",
      "1. Amchur\n",
      "2. Karela\n",
      "3. Red chilli powder\n",
      "4. Gram flour\n",
      "5. Onion\n",
      "6. Cumin seeds\n",
      "7. Coriander powder\n",
      "8. Turmeric powder\n",
      "9. Sunflower oil\n",
      "\n",
      "Instructions:\n",
      "0. Step 1: Soak the gram flour in water for about 30 minutes to make it smooth and easy to grind.\n",
      "1. Step 2: Heat sunflower oil in a pan over medium heat, add cumin seeds and let them sizzle for a few seconds.\n",
      "2. Step 3: Add chopped onion and sauté until they are translucent and lightly browned.\n",
      "3. Step 4: Grind the soaked gram flour into a fine paste with turmeric powder, red chilli powder, coriander powder, and salt.\n",
      "4. Step 5: Add the ground spice mixture to the pan with onion and mix well.\n",
      "5. Step 6: Slice the karela into thin rounds, remove excess moisture by salting and draining.\n",
      "6. Step 7: Dip the sliced karela in the gram flour paste, coating them evenly, then add the amchur powder for extra flavor.\n",
      "7. Step 8: Heat some oil in a pan over medium heat, add the coated karela slices and fry until they are golden brown and crispy.\n"
     ]
    }
   ],
   "source": [
    "lines = response.split(\"\\n\")\n",
    "\n",
    "gen_ingredients = []\n",
    "gen_instructions = []\n",
    "\n",
    "current_section = None\n",
    "\n",
    "for line in lines:\n",
    "    stripped_line = line.strip()  \n",
    "    \n",
    "    if stripped_line == 'Ingredients Used:':\n",
    "        current_section = 'ingredients'\n",
    "        continue  \n",
    "    elif stripped_line == 'Instructions:':\n",
    "        current_section = 'instructions'\n",
    "        continue \n",
    "    elif stripped_line.startswith('- '):\n",
    "        # Extract the item after '- '\n",
    "        item = stripped_line[2:].strip()\n",
    "        if current_section == 'ingredients':\n",
    "            gen_ingredients.append(item)\n",
    "        elif current_section == 'instructions':\n",
    "            gen_instructions.append(item)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(\"Ingredients:\")\n",
    "for idx, ingredient in enumerate(gen_ingredients):\n",
    "    print(f\"{idx}. {ingredient}\")\n",
    "\n",
    "print(\"\\nInstructions:\")\n",
    "for idx, instruction in enumerate(gen_instructions):\n",
    "    print(f\"{idx}. {instruction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salt',\n",
       " 'amchur',\n",
       " 'karela',\n",
       " 'red chilli powder',\n",
       " 'gram flour',\n",
       " 'onion',\n",
       " 'cumin seeds',\n",
       " 'coriander powder',\n",
       " 'turmeric powder',\n",
       " 'sunflower oil']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Processed_Ingredients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "actual_ingredients=data['Processed_Ingredients'][0]\n",
    "gen_ingredients_lower = [ingredient.lower() for ingredient in gen_ingredients]\n",
    "\n",
    "total_input_ingredients = len(actual_ingredients)\n",
    "total_ingredients_used = len(gen_ingredients_lower)\n",
    "\n",
    "relevant_ingredients_used = len(set(actual_ingredients).intersection(set(gen_ingredients_lower)))\n",
    "\n",
    "precision = relevant_ingredients_used / total_ingredients_used\n",
    "recall = relevant_ingredients_used / total_input_ingredients\n",
    "\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To begin making the Masala Karela Recipe,de-seed the karela and slice.\\nDo not remove the skin as the skin has all the nutrients.\\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\\nRelease the pressure immediately and open the lids.\\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\\n']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TranslatedInstructions'][0].split('/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Step 1: Soak the gram flour in water for about 30 minutes to make it smooth and easy to grind.',\n",
       " 'Step 2: Heat sunflower oil in a pan over medium heat, add cumin seeds and let them sizzle for a few seconds.',\n",
       " 'Step 3: Add chopped onion and sauté until they are translucent and lightly browned.',\n",
       " 'Step 4: Grind the soaked gram flour into a fine paste with turmeric powder, red chilli powder, coriander powder, and salt.',\n",
       " 'Step 5: Add the ground spice mixture to the pan with onion and mix well.',\n",
       " 'Step 6: Slice the karela into thin rounds, remove excess moisture by salting and draining.',\n",
       " 'Step 7: Dip the sliced karela in the gram flour paste, coating them evenly, then add the amchur powder for extra flavor.',\n",
       " 'Step 8: Heat some oil in a pan over medium heat, add the coated karela slices and fry until they are golden brown and crispy.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To begin making the Masala Karela Recipe,de-seed the karela and slice.\\nDo not remove the skin as the skin has all the nutrients.\\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\\nRelease the pressure immediately and open the lids.\\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TranslatedInstructions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.7126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# reference_text = data['TranslatedInstructions'][0]\n",
    "# reference_sentences = re.split(r'[.\\n]', reference_text)\n",
    "\n",
    "# reference_tokens = [word_tokenize(sent.lower()) for sent in reference_sentences if sent.strip()]\n",
    "# reference_tokens_flat = [token for sent in reference_tokens for token in sent]\n",
    "\n",
    "# candidate_sentences = gen_instructions\n",
    "# candidate_tokens = [word_tokenize(sent.lower()) for sent in candidate_sentences]\n",
    "\n",
    "# candidate_tokens_flat = [token for sent in candidate_tokens for token in sent]\n",
    "\n",
    "\n",
    "reference_tokens = data['TranslatedInstructions'][0].split('/n')\n",
    "candidate_text='\\n '.join(gen_instructions)\n",
    "candidate_tokens = candidate_text\n",
    "weights = (0.5, 0.5)\n",
    "bleu_score = sentence_bleu(reference_tokens, candidate_tokens,weights=weights)\n",
    "\n",
    "# weights = (1.0, 0)\n",
    "\n",
    "# smooth = SmoothingFunction().method4\n",
    "\n",
    "# bleu_score = sentence_bleu(\n",
    "#     [reference_tokens_flat],  \n",
    "#     candidate_tokens_flat,    \n",
    "#     weights=weights,\n",
    "#     smoothing_function=smooth\n",
    "# )\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = re.findall(r'\\* (.+)', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salt',\n",
       " 'Amchur',\n",
       " 'Karela',\n",
       " 'Red chilli powder',\n",
       " 'Gram flour',\n",
       " 'Onion',\n",
       " 'Cumin seeds',\n",
       " 'Coriander powder',\n",
       " 'Turmeric powder',\n",
       " 'Heat sunflower oil in a pan over medium heat.',\n",
       " 'Add cumin seeds and let them sizzle for a few seconds.',\n",
       " 'Add finely chopped onion and sauté until it is translucent.',\n",
       " 'Add karela (bitter gourd) and sauté for 2-3 minutes, or until it starts to soften.',\n",
       " 'Add salt, red chilli powder, coriander powder, and turmeric powder, and mix well.',\n",
       " 'Add gram flour (besan) and mix well.',\n",
       " 'Add amchur (dried mango powder) and mix well.',\n",
       " 'Cover the pan and cook for 5-7 minutes, or until the karela is cooked through and the mixture is dry.',\n",
       " 'Serve hot with rice or roti.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salt',\n",
       " 'amchur',\n",
       " 'karela',\n",
       " 'red chilli powder',\n",
       " 'gram flour',\n",
       " 'onion',\n",
       " 'cumin seeds',\n",
       " 'coriander powder',\n",
       " 'turmeric powder',\n",
       " 'sunflower oil']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Processed_Ingredients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To begin making the Masala Karela Recipe,de-seed the karela and slice.\\nDo not remove the skin as the skin has all the nutrients.\\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\\nRelease the pressure immediately and open the lids.\\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TranslatedInstructions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salt',\n",
       " 'amchur',\n",
       " 'karela',\n",
       " 'red chilli powder',\n",
       " 'gram flour',\n",
       " 'onion',\n",
       " 'cumin seeds',\n",
       " 'coriander powder',\n",
       " 'turmeric powder',\n",
       " 'sunflower oil']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Processed_Ingredients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for Llama2LLMChain\nprompt\n  Field required [type=missing, input_value={'llm': <transformers.pip... at 0x000001E5AA1EA1E0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<transformers.pipelines.t...t at 0x000001E5AA1EA1E0>, input_type=TextGenerationPipeline]\n    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<transformers.pipelines.t...t at 0x000001E5AA1EA1E0>, input_type=TextGenerationPipeline]\n    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Initialize the LLaMA model as part of LangChain\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m llama_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLlama2LLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_recipe\u001b[39m(ingredients: \u001b[38;5;28mlist\u001b[39m, cuisine: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Convert the ingredients list into a comma-separated string\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     ingredients_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ingredients)\n",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m, in \u001b[0;36mLlama2LLMChain.__init__\u001b[1;34m(self, model, tokenizer)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, tokenizer):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:215\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     emit_warning()\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\langchain_core\\load\\serializable.py:112\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arnab\\.conda\\envs\\data_science\\Lib\\site-packages\\pydantic\\main.py:176\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    175\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 3 validation errors for Llama2LLMChain\nprompt\n  Field required [type=missing, input_value={'llm': <transformers.pip... at 0x000001E5AA1EA1E0>}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<transformers.pipelines.t...t at 0x000001E5AA1EA1E0>, input_type=TextGenerationPipeline]\n    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of\nllm.is-instance[Runnable]\n  Input should be an instance of Runnable [type=is_instance_of, input_value=<transformers.pipelines.t...t at 0x000001E5AA1EA1E0>, input_type=TextGenerationPipeline]\n    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "access_token = \"\"\n",
    "\n",
    "# Specify the model\n",
    "model_name = \"openai-community/gpt2\"\n",
    "\n",
    "# Try loading the fast tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, use_auth_token=access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, use_auth_token=access_token)\n",
    "\n",
    "\n",
    "# Define a custom prompt template for generating recipes\n",
    "recipe_template = \"\"\"\n",
    "I have the following ingredients: {ingredients}.\n",
    "I want to prepare a dish from {cuisine} cuisine.\n",
    "Please generate a recipe using these ingredients with instructions.\n",
    "\n",
    "Recipe:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"ingredients\", \"cuisine\"],\n",
    "    template=recipe_template\n",
    ")\n",
    "\n",
    "# LangChain LLM wrapper for Hugging Face model\n",
    "class Llama2LLMChain(LLMChain):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        super().__init__(llm=pipeline(\"text-generation\", model=model, tokenizer=tokenizer))\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        return super()._call(inputs)\n",
    "\n",
    "# Initialize the LLaMA model as part of LangChain\n",
    "llama_chain = Llama2LLMChain(model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def generate_recipe(ingredients: list, cuisine: str) -> str:\n",
    "    # Convert the ingredients list into a comma-separated string\n",
    "    ingredients_str = ', '.join(ingredients)\n",
    "    \n",
    "    # Prepare input data for the LangChain\n",
    "    input_data = {\n",
    "        \"ingredients\": ingredients_str,\n",
    "        \"cuisine\": cuisine\n",
    "    }\n",
    "    \n",
    "    # Generate the recipe using the LLaMA model\n",
    "    response = llama_chain(input_data)\n",
    "    \n",
    "    # Extract and return the generated text\n",
    "    return response['text']\n",
    "\n",
    "ingredients = data['Processed_Ingredients'][0]\n",
    "cuisine = 'Indian'\n",
    "\n",
    "recipe = generate_recipe(ingredients, cuisine)\n",
    "print(recipe)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
